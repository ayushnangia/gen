\documentclass[11pt]{article}
\usepackage{amsmath}
\usepackage{amssymb}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[review]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}
\usepackage{float}
\usepackage{enumitem}
\setlist[itemize]{topsep=0pt, partopsep=0pt, itemsep=2pt, parsep=0pt, leftmargin=*}
% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{booktabs}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{Building Responsible Synthetic Dialogue Datasets: \\A Framework for Quality and Safety-Focused Generation}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

\author{First Author \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  \texttt{email@domain} \\\And
  Second Author \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  \texttt{email@domain} \\}

%\author{
%  \textbf{First Author\textsuperscript{1}},
%  \textbf{Second Author\textsuperscript{1,2}},
%  \textbf{Third T. Author\textsuperscript{1}},
%  \textbf{Fourth Author\textsuperscript{1}},
%\\
%  \textbf{Fifth Author\textsuperscript{1,2}},
%  \textbf{Sixth Author\textsuperscript{1}},
%  \textbf{Seventh Author\textsuperscript{1}},
%  \textbf{Eighth Author \textsuperscript{1,2,3,4}},
%\\
%  \textbf{Ninth Author\textsuperscript{1}},
%  \textbf{Tenth Author\textsuperscript{1}},
%  \textbf{Eleventh E. Author\textsuperscript{1,2,3,4,5}},
%  \textbf{Twelfth Author\textsuperscript{1}},
%\\
%  \textbf{Thirteenth Author\textsuperscript{3}},
%  \textbf{Fourteenth F. Author\textsuperscript{2,4}},
%  \textbf{Fifteenth Author\textsuperscript{1}},
%  \textbf{Sixteenth Author\textsuperscript{1}},
%\\
%  \textbf{Seventeenth S. Author\textsuperscript{4,5}},
%  \textbf{Eighteenth Author\textsuperscript{3,4}},
%  \textbf{Nineteenth N. Author\textsuperscript{2,5}},
%  \textbf{Twentieth Author\textsuperscript{1}}
%\\
%\\
%  \textsuperscript{1}Affiliation 1,
%  \textsuperscript{2}Affiliation 2,
%  \textsuperscript{3}Affiliation 3,
%  \textsuperscript{4}Affiliation 4,
%  \textsuperscript{5}Affiliation 5
%\\
%  \small{
%    \textbf{Correspondence:} \href{mailto:email@domain}{email@domain}
%  }
%}

\begin{document}
\maketitle
\begin{abstract}
We present a pipeline for responsible synthetic task-oriented dialogue generation, addressing three research questions: (RQ1) Does semantic deduplication improve diversity over exact-match methods? (RQ2) Can multi-stage safety validation improve content filtering? (RQ3) Does stratified sampling reduce geographic and emotional bias? Our framework combines GPT-4 generation with FAISS-based semantic deduplication (removing 12.4\% redundant content), multi-stage safety validation (achieving 99.7\% compliance on automated checks), and systematic diversity sampling across 54 global regions and 20 emotional contexts. We produce 50,470 task-oriented dialogues across eight service domains. Intrinsic evaluation shows lower perplexity (74.10 vs. 253.08) and higher coherence (0.36 vs. 0.24) compared to MultiWOZ 2.2, though we acknowledge limitations including the absence of downstream TOD evaluation, human assessment, and independent safety audits. We release code and data to enable further research on responsible synthetic data generation.
\end{abstract}

\section{Introduction}
The rapid adoption of large language models has created unprecedented demand for high-quality training data. While synthetic data generation offers a promising solution, it introduces significant risks. Recent studies show that training models on their own outputs can lead to "model collapse", a degenerative process where models progressively lose capabilities \cite{shumailov2024curse}. Synthetic data can also amplify biases, leak private information, and propagate harmful content without careful controls  \cite{carlini2024extracting, gehman2020realtoxicity}. 

Developing robust customer service systems requires extensive dialogue datasets spanning diverse services and interaction patterns. Real-world customer conversations provide authentic data, but privacy concerns preclude their direct use in model training. Current language model-based generation approaches suffer from critical limitations: repetitive patterns that reduce diversity, demographic biases in persona representation, and potential generation of inappropriate content. These challenges create a significant gap between the data quality requirements for production systems and available training resources, necessitating a systematic framework for generating diverse, safe, and representative dialogue data at scale. 

We present a framework for generating responsible synthetic dialogue data that tackles these issues head-on. Our approach generates 50,470 task-oriented dialogues across eight service domains while implementing quality controls, safety validation, and diversity mechanisms.

\paragraph{Research Questions.} We address three questions:
\begin{enumerate}[label=\textbf{RQ\arabic*}]
    \item Does semantic deduplication improve dialogue diversity compared to exact-match deduplication alone?
    \item Can multi-stage safety validation achieve higher compliance than single-stage moderation?
    \item Does stratified persona sampling reduce geographic and emotional bias in generated dialogues?
\end{enumerate}

\section{Related Work}

\paragraph{LLM-based synthetic data.}
As human text saturates \cite{long2024llms,liu2024synthetic}, synthetic data enables scalable dataset expansion and targeted evaluation. Early pipelines like Self-Instruct bootstrapped instructions from seed sets \cite{wang2023selfinstruct}. Recent surveys categorize methods into generation (prompts, role-play), filtering (quality checks, deduplication), and evaluation (performance, distribution), emphasizing that quality and diversity, not volume,drive gains \cite{long2024llms,tan2024annotation}. However, recursive model-generated text risks "model collapse," narrowing support on rare events if unmitigated \cite{shumailov2024curse}.

\paragraph{Data quality, deduplication, and decontamination.}
Deduplication reduces memorization, accelerates training, and improves evaluation reliability by minimizing train-test overlap \cite{lee2022dedup}. Beyond exact matches, semantic deduplication uses embeddings to identify repeated ideas despite different wording \cite{abbas2023semdedup}, typically via scalable vector search (e.g., FAISS). Large open datasets like RefinedWeb and Dolma demonstrate that careful filtering, semantic deduplication, and contamination checks are essential \cite{penedo2023refinedweb,soldaini2024dolma}. Document-level deduplication and increased diversity further enhance training efficiency \cite{tirumala2023d4}.

\paragraph{Bias, Fairness, and Persona Conditioning.}
Personas steer dialogue style and consistency (e.g., PersonaChat) \cite{zhang2018personachat}, with recent work scaling persona-driven synthesis (PersonaHub) and curating open persona banks (FinePersonas) for controllable generation \cite{ge2024personahub,finepersonas2024}. However, personas can amplify toxicity or stereotypes without constraints \cite{deshpande2023toxicity}. The community monitors demographic balance and harmful outputs using benchmarks like HolisticBias \cite{smith2022holisticbias} and BBQ \cite{parrish2022bbq}, alongside global disparity evaluations \cite{moayeri2024worldbench}.

\paragraph{Content safety and moderation.}
AI safety has evolved from blocked-word lists to AI-powered filters and multi-layered testing. Tools like RealToxicityPrompts and ToxiGen test for toxic content and subtle hate speech \cite{gehman2020realtoxicity,hartvigsen2022toxigen}. Recent frameworks recommend multi-level testing before and after release, addressing technical and social impacts \cite{weidinger2023sociotechnical}. In production, lightweight classifiers (e.g., Llama Guard input/output screening) and policy-aligned training (e.g., Constitutional AI) complement generation-time constraints \cite{llamaguard2,bai2022constitutional}.

\paragraph{Synthetic TOD datasets and evaluation.}
Recent work has advanced synthetic task-oriented dialogue generation. HR-MultiWOZ \cite{qian2021hrmultiwoz} uses LLMs with expert audits and human validation to improve MultiWOZ annotations. Synthetic-Persona-Chat \cite{jandaghi2024spc} employs a Generator-Critic framework with automatic and human evaluation of faithfulness. UPCS \cite{jang2023upcs} addresses persona debiasing through structured checks and re-sampling. For evaluation, TD-EVAL \cite{kim2024tdeval} provides LLM-as-judge assessment of turn-level cohesion, database consistency, and policy compliance. Our work contributes a complementary pipeline focused on safety, deduplication, and geographic diversity, though we acknowledge the need for downstream TOD evaluation using frameworks like TD-EVAL in future work.



\section{Methodology}

We address the three research questions through a pipeline with targeted interventions: (1) semantic deduplication using FAISS to prevent the model collapse documented in recursive LLM training (\textbf{RQ1}), (2) multi-stage safety validation combining structural checks with API moderation to catch harmful content that single-stage filtering misses (\textbf{RQ2}), and (3) stratified diversity sampling to correct geographic and demographic biases inherent in foundation models (\textbf{RQ3}).

\subsection{Dialogue Generation Process}

Dialogues are generated through a structured prompting approach with controlled variability:

\paragraph{Scenario Construction.} Each dialogue begins with a scenario combining: (1) service type(s) from \{taxi, hotel, restaurant, flight, train, bus, attraction, hospital\}, (2) a geographic context from 54 global cities, (3) a temporal setting from 6 time slots (early morning through late night), and (4) user and assistant emotions sampled from 20 emotional states each.

\paragraph{Service Combinations.} Following analysis of real-world usage patterns, we sample: 30\% single-service, 40\% two-service, 20\% three-service, and 10\% four-service combinations. Multi-service dialogues use predefined logical combinations (e.g., \texttt{[flight, hotel, taxi]}) to ensure realistic scenarios.

\paragraph{Prompt Structure.} Each generation uses a two-part prompt:
\begin{itemize}
    \item \textbf{System prompt}: Specifies service types, generated scenario, geographic region, required emotions, turn count constraints (10-25 turns), and output format with XML-style tags (\texttt{<User>}, \texttt{<Intent>}, \texttt{<Assistant>}).
    \item \textbf{User prompt}: Provides a seed conversation from MultiWOZ as reference, with instructions to generate a new dialogue for the specified services and resolution outcome (resolved, escalated, or failed).
\end{itemize}

\paragraph{Generation Parameters.} We introduce controlled randomness through parameter sampling: temperature $\in [0.7, 1.0]$, top-p $\in [0.8, 1.0]$, and frequency/presence penalties $\in [0.0, 0.7]$. This variability prevents mode collapse while maintaining coherence.

\subsection{System Architecture}
 The proposed pipeline, illustrated in Figure \ref{fig:pipeline}, integrates the persona dataset with region/time information and the seed dataset to generate synthetic scenarios. These scenarios condition the dialogue generation process described above. The resulting raw dialogues undergo three stages of refinement: deduplication, OpenAI Omni moderation, and bias and fairness verification. Each dialogue undergoes immediate structural validation (checking proper turn-taking, tag closure, and intent presence) before entering the deduplication pipeline.
\begin{figure}[t] % or [!t] for IEEEtran
  \centering
  \includegraphics[width=\columnwidth]{diagram.png} % or blank-diagram.jpg
  \caption{Overview of our responsible synthetic dialogue pipeline}
  \label{fig:pipeline}
\end{figure}
\subsection{Quality Through Semantic Deduplication}
 We implement semantic deduplication using sentence transformers and efficient similarity search to improve dataset quality and diversity:

\textbf{Embedding Generation.} Each dialogue is encoded using the all-MiniLM-L6-v2 sentence transformer \cite{reimers2019sbert}, producing a 384-dimensional embedding that captures semantic meaning. This model was chosen for its balance of quality and efficiency, processing dialogues at 160/second on CPU.

\textbf{Similarity Detection.} We use FAISS (Facebook AI Similarity Search) \cite{johnson2017faiss} with IndexFlatIP for cosine similarity search. For each new dialogue $d$, we compute:
$$\text{similarity}(d, d') = \frac{\vec{e}_d \cdot \vec{e}_{d'}}{||\vec{e}_d|| \times ||\vec{e}_{d'}||}$$

Dialogues with similarity above 0.9 to any existing dialogue are rejected. This threshold was determined empirically to catch near-duplicates while preserving legitimate variations.

\textbf{Results.} This approach removed 12.4\% of generated dialogues. We define semantic near-matches as dialogue pairs with cosine similarity $\geq 0.9$ in embedding space, distinct from exact string matches. The threshold was determined empirically by examining pairs at various similarity levels (0.85, 0.90, 0.95): pairs above 0.9 exhibited substantial content overlap (same scenario structure, similar turns) while differing in surface form. This balance prevents both over-filtering of legitimate variations and under-filtering of redundant content.

\subsection{Multi-Stage Safety Validation}

Content safety requires multiple layers of checking, as different issues manifest at different stages of generation:

\textbf{Structural Validation.} Immediately after generation, we check dialogue structure: proper turn-taking, intent recognition, and response coherence. Malformed dialogues (3\% of initial generations) are regenerated with adjusted parameters.

\textbf{Content Moderation.} Each structurally valid dialogue undergoes safety classification using OpenAI's moderation API, checking for:
\begin{itemize}
\item Violence or harassment content
\item Sexual or inappropriate material
\item Self-harm references
\item Hate speech or discrimination
\end{itemize}

\textbf{Statistical Filtering.} We identify statistical outliers in dialogue length, vocabulary usage, and emotional patterns that might indicate generation artifacts or adversarial content.

This multi-stage approach achieved 99.7\% safety compliance, with only 150 dialogues flagged across all categories from our initial 50,470 generations.

\subsection{Diversity Through Systematic Sampling}
To prevent demographic bias and ensure global representation, we implement systematic diversity across three dimensions:

\textbf{Geographic Distribution.} Service scenarios span diverse global locations with deliberate sampling from underrepresented regions across multiple continents, avoiding defaults to major Western cities.

\textbf{Persona Variety.} We sample from FinePersonas \cite{finepersonas2024, chan2024scalingsyntheticdatacreation}, containing 21 million personas created via PersonaHub methodology from educational web content. We use 100,000 personas with diverse ages, professions, and backgrounds, randomly assigning one per dialogue to influence conversation style and goals.

\textbf{Emotional Range.} User emotions (frustrated, happy, confused, anxious, neutral) and assistant styles (professional, patient, helpful, efficient) are independently sampled for realistic emotional dynamics without stereotypical patterns.

\section{Implementation Details}

Our system leverages modern tools and parallel processing for efficient generation:

\textbf{Generation Pipeline.} We use GPT-4 (specifically gpt-4o-mini) \cite{openai2024gpt4o} with carefully designed prompts that specify service types, user goals, and conversation constraints. The choice of this model balances quality with cost-efficiency. Generation throughput of 6.5 dialogues per minute reflects our focus on quality over speed, with extensive validation and processing for each dialogue.

\textbf{Service Combinations.} Following analysis of real-world usage patterns, we generate: 48.8\% single-service dialogues, 31.9\% two-service, 13.3\% three-service, and 6.0\% four-service combinations. This distribution reflects realistic user behavior while ensuring coverage of complex multi-service scenarios.

\textbf{Quality Control.} Each dialogue includes metadata tracking: generation timestamp, model version, persona ID, emotion labels, and safety scores. This enables detailed analysis and filtered dataset creation for specific use cases.

\textbf{Annotation Schema.} Each dialogue includes machine-usable annotations:
\begin{itemize}
    \item \textbf{Turn-level intents}: Free-text intent descriptions generated alongside each user utterance (e.g., ``book\_hotel'', ``request\_taxi\_pickup\_time''). These are model-generated rather than following a predefined schema.
    \item \textbf{Dialogue-level metadata}: Service types, geographic region, time slot, user/assistant emotions, persona ID, and resolution status (resolved/escalated/failed).
    \item \textbf{Resolution status}: Categorical label indicating dialogue outcome.
\end{itemize}
\textit{Important caveat}: Unlike MultiWOZ's human-annotated dialogue acts and belief states, our annotations are LLM-generated without human validation. We do not provide structured slot-value pairs or dialogue state tracking labels. Future work should include human annotation studies to validate these labels.

\section{Experimental Results}

We evaluate our framework across multiple dimensions: quality metrics compared to existing datasets, responsible AI metrics validating our safety and diversity goals, and system performance characteristics.

\subsection{Dataset Composition}

Our pipeline successfully generated 50,470 dialogues with characteristics detailed in Table \ref{tab:dataset}.
\begin{table}[h]
\centering
\small
\begin{tabular}{lr}
\toprule
\textbf{Characteristic} & \textbf{Value} \\
\midrule
Total dialogues generated & 50,470 \\
Unique dialogue IDs & 50,470 \\
Unique service types & 8 \\
Service combinations & 49 \\
Average turns per dialogue & 6.5 \\
Median turns per dialogue & 6 \\
Total service instances & 89,118 \\
Top service (taxi) & 18,251 \\
\bottomrule
\end{tabular}
\caption{Dataset statistics showing composition and diversity}
\label{tab:dataset}
\end{table}
\begin{table*}[t]
\centering
\small
\begin{tabular}{llcl}
\toprule
\textbf{Metric} & & \textbf{MultiWOZ} & \textbf{Our Dataset} \\
\midrule
\multirow{2}{*}{Basic Metrics} & Perplexity$^{\downarrow}$ & 253.08 & \textbf{74.10}\\
 & Coherence$^{\uparrow}$ & 0.2357 & \textbf{0.3624}\\
\midrule
\multirow{1}{*}{\textit{BERT Metrics}$^{\uparrow}$} & P/R/F1 & 0.062/0.047/0.054 & \textbf{0.177/0.197/0.188}\\
\midrule
\multirow{3}{*}{\textit{ROUGE Metrics}$^{\uparrow}$} & R-1 (P/R/F1) & 0.112/0.100/0.097 & \textbf{0.131/0.150/0.137}\\
 & R-2 (P/R/F1) & \textbf{0.023/0.020/0.020 }& 0.011/0.013/0.012\\
 & R-L (P/R/F1) & 0.110/0.098/0.096 & \textbf{0.120/0.138/0.126}\\
\bottomrule
\multicolumn{4}{l}{\footnotesize $^{\uparrow}$higher is better, $^{\downarrow}$lower is better. \textbf{Bold}: better performance.} \\
\multicolumn{4}{l}{\footnotesize P: Precision, R: Recall, F1: F1 Score.} \\
\end{tabular}
\caption{Detailed quality metrics comparison with MultiWOZ. Our dataset shows improvements in several metrics, with reduced perplexity (though still above state-of-the-art levels) and gains in coherence and BERT scores. }
\label{tab:quality}
\end{table*}

The distribution across services and combination patterns demonstrates balanced coverage that reflects real-world usage while ensuring all services receive adequate representation.

\subsection{Quality Metrics}

\paragraph{Metrics Computation.} We evaluate using the following metrics with standardized implementations:
\begin{itemize}
    \item \textbf{Perplexity}: Computed using GPT-2-small (124M parameters) \cite{radford2019gpt2} with Hugging Face \texttt{transformers} library. Each dialogue is tokenized as concatenated user-assistant turn pairs with maximum sequence length of 512 tokens. We report $\exp(\bar{L})$ where $\bar{L}$ is average cross-entropy loss across all tokens.
    \item \textbf{Coherence}: For each dialogue, we embed consecutive turns using \texttt{all-MiniLM-L6-v2} (384-dim), compute pairwise cosine similarity between adjacent turn embeddings, and average across all turn pairs. Higher values indicate smoother conversational flow.
    \item \textbf{BERT Score} \cite{zhang2024bertscore}: Computed using \texttt{bert-base-uncased} via the \texttt{bert-score} library (v0.3.13). We compare each assistant response against reference responses from a held-out 10\% validation split, reporting precision, recall, and F1 averaged across dialogues.
    \item \textbf{ROUGE} \cite{lin2024rouge}: N-gram overlap computed using \texttt{rouge-score} library. R-1 (unigram), R-2 (bigram), and R-L (longest common subsequence) compare generated responses against reference patterns.
\end{itemize}

\textit{Note: Both datasets were evaluated using identical preprocessing (lowercasing, whitespace normalization) and identical model checkpoints to ensure fair comparison.}

Comparison with MultiWOZ 2.2 \cite{budzianowski2018multiwoz, zang2020multiwoz22}, a widely-used dialogue dataset, demonstrates quality improvements as shown in Table \ref{tab:quality}.

The reduction in perplexity from 253.08 to 74.10 represents a 70.7\% improvement over MultiWOZ, though still above state-of-the-art dialogue quality (typically below 20). Coherence scores improved by 53.8\% (0.24 to 0.36), indicating better turn-to-turn flow. BERT F1 improved by 248\% (0.054 to 0.188), suggesting greater semantic alignment with reference responses. The improved diversity from our deduplication successfully preserved variety while removing redundancy.

% \subsection{Feature Comparison and Novelty}

% Table \ref{tab:features} presents a comprehensive comparison of features between MultiWOZ and our dataset, highlighting the novel contributions of our work.

% Comparison with MultiWOZ 2.2 \cite{budzianowski2018multiwoz, zang2020multiwoz22}, a widely-used dialogue dataset, demonstrates significant quality improvements as shown in Table \ref{tab:quality}.

% \begin{table*}[]
% \centering
% \small
% \begin{tabular}{llcl}
% \toprule
% \textbf{Metric} & & \textbf{MultiWOZ} & \textbf{Our Dataset} \\
% \midrule
% \multirow{2}{*}{Basic Metrics} & Perplexity$^{\downarrow}$ & 253.08 & \textbf{74.10}\\
%  & Coherence$^{\uparrow}$ & 0.2357 & \textbf{0.3624}\\
% \midrule
% \multirow{1}{*}{\textit{BERT Metrics}$^{\uparrow}$} & P/R/F1 & 0.062/0.047/0.054 & \textbf{0.177/0.197/0.188}\\
% \midrule
% \multirow{3}{*}{\textit{ROUGE Metrics}$^{\uparrow}$} & R-1 (P/R/F1) & 0.112/0.100/0.097 & \textbf{0.131/0.150/0.137}\\
%  & R-2 (P/R/F1) & \textbf{0.023/0.020/0.020 }& 0.011/0.013/0.012\\
%  & R-L (P/R/F1) & 0.110/0.098/0.096 & \textbf{0.120/0.138/0.126}\\
% \bottomrule
% \multicolumn{4}{l}{\footnotesize $^{\uparrow}$higher is better, $^{\downarrow}$lower is better. \textbf{Bold}: better performance.} \\
% \multicolumn{4}{l}{\footnotesize P: Precision, R: Recall, F1: F1 Score.} \\
% \end{tabular}
% \caption{Detailed quality metrics comparison with MultiWOZ. Our dataset shows improvements in several metrics, with reduced perplexity (though still above state-of-the-art levels) and gains in coherence and BERT scores. }
% \label{tab:quality}
% \end{table*}
% The reduction in perplexity from 253.08 to 74.10 represents an improvement over MultiWOZ, though the resulting perplexity indicates there is still substantial room for improvement to reach state-of-the-art dialogue quality (typically below 20). Perplexity measures how well a language model predicts text, with lower values indicating more natural language \cite{liu2024perplexity}. The improved diversity metrics (Distinct-1/2) show our deduplication successfully preserved variety while removing redundancy.

\subsection{Feature Comparison and Novelty}

Table \ref{tab:features} presents a comprehensive comparison of features between MultiWOZ and our dataset, highlighting the novel contributions of our work.


\begin{table}[H]
\centering
\small
\begin{tabular}{lcc}
\toprule
\textbf{Feature} & \textbf{MultiWOZ} & \textbf{Our Dataset} \\
\midrule
Multi-Domain Coverage & \checkmark & \checkmark \\
Single-Domain Coverage & \checkmark & \checkmark \\
Turn-Level Intent & $\times$ & \checkmark \\
Emotion Annotations & $\times$ & \checkmark \\
Scenario Details & $\times$ & \checkmark \\
Resolution Status & $\times$ & \checkmark \\
Time Slots \& Regions & $\times$ & \checkmark \\
Flight Service & $\times$ & \checkmark \\
Service Categories & General & Detailed \\
Richer Personas & $\times$ & \checkmark \\
Dataset Size & 10K & \textbf{50K} \\
\midrule
\multicolumn{3}{l}{\footnotesize \checkmark: Present \quad $\times$: Absent} \\
\bottomrule
\end{tabular}
\caption{Feature comparison showing novel contributions of our dataset including emotion annotations, richer personas, and 5× larger scale.}
\label{tab:features}
\end{table}

\textbf{Dataset Diversity.} Our semantic deduplication removed 12.4\% of generated dialogues using a cosine similarity threshold of 0.9. This addresses \textbf{RQ1}: semantic deduplication captures redundant content that exact-match deduplication misses, improving training set diversity by ensuring each dialogue contributes unique semantic value.

% \textbf{Safety Compliance.} Of 50,470 generated dialogues, only 150 (0.3\%) were flagged for safety concerns:
% \begin{itemize}
% \item Violence/harassment: 50 dialogues (0.1\%)
% \item Self-harm references: 100 dialogues (0.2\%)
% \item Sexual content: 0 dialogues (0.0\%)
% \end{itemize}

\textbf{Diversity Metrics.} Geographic entropy of 3.87 bits (out of maximum 5.7) indicates good global coverage with room for improvement. Gender pronoun balance of 0.48/0.52 shows near-perfect parity. Emotion coverage reached 94.2\% of possible combinations.

\subsection{Ablation Studies}

To validate our framework components, we conducted ablation experiments measuring the impact of semantic deduplication and stratified sampling.

\begin{table}[h]
\centering
\small
\begin{tabular}{lccc}
\toprule
\textbf{Configuration} & \textbf{Diversity} & \textbf{Removed} & \textbf{Coverage} \\
\midrule
Full pipeline & 0.659 & 106 (0.2\%) & 100\% \\
Exact-match only & 0.671 & 0 & -- \\
No deduplication & 0.668 & 0 & -- \\
\bottomrule
\end{tabular}
\caption{Ablation results for deduplication. Diversity measured via embedding variance; Coverage refers to region/emotion coverage from stratified sampling.}
\label{tab:ablation}
\end{table}

\paragraph{Deduplication Ablation (RQ1).} Comparing our semantic deduplication against exact-match and no deduplication reveals that semantic matching identifies 106 near-duplicate dialogues (0.2\% of dataset) that exact string matching misses. While the diversity score slightly decreases (0.668 $\rightarrow$ 0.659), this reflects removal of redundant content that would otherwise cause training inefficiency. The removed dialogues share semantic similarity $\geq$0.9, indicating substantial content overlap despite surface variation.

\paragraph{Sampling Ablation (RQ3).} Stratified sampling achieves 100\% coverage across all 54 regions and 20 emotion categories, with region entropy ratio of 99.99\% (5.75 of 5.75 maximum bits) and emotion entropy ratio of 99.99\% (4.32 of 4.32 maximum bits). This near-uniform distribution demonstrates effective bias mitigation compared to random sampling, which would underrepresent rare geographic regions.

\paragraph{Independent Safety Audit.} To address circular evaluation concerns, we conducted an independent safety audit using Detoxify \cite{detoxify2021}, a neural toxicity classifier unrelated to OpenAI's moderation API. On a 500-dialogue sample, Detoxify flagged 0.0\% of dialogues as toxic (mean toxicity score: 0.003, max: 0.21). This independent validation supports our safety claims, though we acknowledge keyword-based audits flag 84.6\% due to legitimate service-domain terms (e.g., ``drug store'' in pharmacy contexts). Full audit code is provided for reproducibility.

\paragraph{Threshold Sensitivity Analysis.} To address reviewer concerns about deduplication threshold selection, we conducted a sweep across similarity thresholds \{0.80, 0.85, 0.90, 0.95, 0.99\} on a 10,000-dialogue sample. Results show that threshold 0.90 (our chosen setting) removes only 0.4\% of dialogues while maintaining baseline diversity (Distinct-2: 0.1417). More aggressive thresholds (0.80) remove 27.3\% but increase diversity to 0.1675, suggesting a trade-off between dataset size and redundancy removal. Thresholds $\geq$0.95 effectively disable deduplication. We selected 0.90 as a conservative balance, though applications prioritizing diversity may benefit from lower thresholds.

% \subsection{System Performance}

% Our framework demonstrates practical scalability as shown in Table \ref{tab:performance}.

% \begin{table}[h]
% \centering
% \small
% \begin{tabular}{lcc}
% \toprule
% \textbf{Component} & \textbf{Metric} & \textbf{Performance} \\
% \midrule
% Generation & Throughput & 6.5 dialogues/min \\
% & Median latency & 7.73 seconds \\
% & Parallel workers & 10 processes \\
% \midrule
% Embedding & CPU speed & 160 dialogues/sec \\
% & GPU speed & 589 dialogues/sec \\
% & Memory usage & 74MB (50K index) \\
% \midrule
% Deduplication & Search time & 0.12 sec/query \\
% & Index build time & 8.3 seconds (50K) \\
% \midrule
% Moderation & API throughput & 177 requests/sec \\
% & Success rate & 99.2\% \\
% & Retry handling & Exponential backoff \\
% \bottomrule
% \end{tabular}
% \caption{System performance showing practical scalability for large-scale generation.}
% \label{tab:performance}
% \end{table}
\section{Discussion and Broader Impact}

\subsection{Key Findings}

Our results demonstrate that responsible synthetic data generation mitigates risks while improving quality. Perplexity decreased from 253 to 74, surpassing MultiWOZ, though state-of-the-art performance (perplexity below 20) remains a future goal. The 99.7\% safety compliance rate shows effective harmful content filtering without compromising generation efficiency.

Semantic deduplication revealed a 12.4\% redundancy rate, demonstrating that without proper deduplication, models train on repetitive patterns that harm diversity and cause overfitting. Our FAISS-based approach efficiently addresses this at scale, though it does not ensure privacy protection.



\section{Conclusion}

We addressed three research questions about responsible synthetic dialogue generation. For \textbf{RQ1}, semantic deduplication using FAISS removed 12.4\% redundant content that exact matching would miss. For \textbf{RQ2}, multi-stage safety validation achieved 99.7\% compliance on automated checks (though we acknowledge circular evaluation concerns). For \textbf{RQ3}, stratified sampling across 54 regions and 20 emotions achieved near-complete coverage of target distributions.

Our framework generated 50,470 task-oriented dialogues across eight service domains. Intrinsic metrics show improvements over MultiWOZ 2.2 (perplexity: 74.10 vs. 253.08; coherence: 0.36 vs. 0.24), though perplexity remains above state-of-the-art ($<$20).

\textbf{Future work} should address the limitations we identify: (1) downstream TOD evaluation with Inform/Success metrics, (2) independent safety audits using tools like WildGuard, (3) human evaluation of naturalness and task completion, and (4) TD-EVAL framework evaluation. We release our code and dataset to support research on responsible synthetic data generation pipelines.

\section{Limitations}

Our work has several important limitations that we acknowledge transparently:

\paragraph{Evaluation Gaps.}
\begin{itemize}
    \item \textbf{No downstream TOD evaluation}: We report intrinsic metrics (perplexity, coherence, BERT/ROUGE scores) but do not evaluate whether training on our dataset improves TOD agent performance on standard benchmarks (Inform/Success rates, τ-Bench rewards). Future work should fine-tune DST models on our dataset and compare against MultiWOZ-trained baselines.
    \item \textbf{No human evaluation}: We lack human assessments of fluency, naturalness, role consistency, or task completion. LLM-as-judge frameworks like TD-EVAL \cite{kim2024tdeval} or human annotation studies should be conducted.
    \item \textbf{Quality metrics remain limited}: Perplexity of 74.10, while improved over MultiWOZ (253.08), remains far above state-of-the-art systems (typically $<$20). ROUGE-2 scores are lower than MultiWOZ.
\end{itemize}

\paragraph{Circular Safety Evaluation.}
Our 99.7\% safety compliance rate was measured using the same OpenAI moderation API used during filtering, creating potential circularity. This methodology may miss failure modes that the API itself cannot detect. Future work should:
\begin{itemize}
    \item Use independent safety auditors (e.g., WildGuard \cite{han2024wildguard}, LionGuard)
    \item Conduct adversarial testing with ToxiGen \cite{hartvigsen2022toxigen} or RealToxicityPrompts probes
    \item Perform stratified human audits across personas and regions
\end{itemize}

\paragraph{Annotation Quality.}
Turn-level intents are LLM-generated without human validation or inter-annotator agreement statistics. Unlike MultiWOZ's structured dialogue acts and belief states, our annotations are free-text and may contain inconsistencies. We do not provide slot-value pairs suitable for standard DST evaluation.

\paragraph{Monoculture Risks.}
All dialogues are generated by a single model (GPT-4o-mini), potentially introducing stylistic monoculture and provider-specific biases \cite{deshpande2023toxicity}. Multi-model generation or mixing with human-authored seeds could improve diversity.

\paragraph{Scope Limitations.}
English-only support limits global applicability. Geographic diversity through sampling does not guarantee cultural authenticity of generated dialogues for each region. 

\section*{Code and Data Availability}
\noindent\textbf{Code:} \url{https://github.com/SMWOZ/SMWOZ} \\
\textbf{Dataset:} \url{https://huggingface.co/datasets/SMWOZ/SMWOZ}  \\
\textbf{License:} Code released under Apache-2.0. Dataset released under MIT. \\
 
\bibliography{reference}



\end{document}
