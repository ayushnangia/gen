@inproceedings{wang2023selfinstruct,
  title={Self-Instruct: Aligning Language Models with Self-Generated Instructions},
  author={Wang, Yizhong and others},
  booktitle={ACL},
  year={2023},
  url={https://arxiv.org/abs/2212.10560}
}

@article{long2024llms,
  title={On LLMs-Driven Synthetic Data Generation, Curation, and Evaluation: A Survey},
  author={Long, Lin and others},
  journal={arXiv:2406.15126},
  year={2024}
}

@article{liu2024synthetic,
  title={A Survey on Data Synthesis and Augmentation for Large Language Models},
  author={Wang, Ke and others},
  journal={arXiv:2410.12896},
  year={2024}
}

@inproceedings{tan2024annotation,
  title={Large Language Models for Data Annotation and Synthesis},
  author={Tan, Zihan and others},
  booktitle={EMNLP},
  year={2024},
  url={https://aclanthology.org/2024.emnlp-main.54}
}

@article{shumailov2024curse,
  title={The Curse of Recursion: Training on Generated Data Makes Models Forget},
  author={Shumailov, Ilia and others},
  journal={arXiv:2305.17493},
  year={2023}
}

@inproceedings{lee2022dedup,
  title={Deduplicating Training Data Makes Language Models Better},
  author={Lee, Katherine and others},
  booktitle={ACL},
  year={2022}
}

@article{abbas2023semdedup,
  title={SemDeDup: Data-Efficient Learning at Web-Scale through Semantic Deduplication},
  author={Abbas, Amro and others},
  journal={arXiv:2303.09540},
  year={2023}
}

@article{penedo2023refinedweb,
  title={The RefinedWeb Dataset for Falcon LLM},
  author={Penedo, Gabriel and others},
  journal={arXiv:2306.01116},
  year={2023}
}

@article{tirumala2023d4,
  title={D4: Improving LLM Pretraining via Document De-Duplication and Diversification},
  author={Tirumala, Kushal and others},
  journal={arXiv:2308.12284},
  year={2023}
}

@misc{soldaini2024dolma,
  title={Dolma: An Open Corpus and Toolkit for Training Language Models},
  author={Soldaini, Luca and others},
  howpublished={Allen AI (dataset + toolkit)},
  year={2024},
  url={https://allenai.org/dolma}
}

@article{johnson2017faiss,
  title={Billion-Scale Similarity Search with GPUs},
  author={Johnson, Jeff and Douze, Matthijs and J{\'e}gou, Herv{\'e}},
  journal={arXiv:1702.08734},
  year={2017}
}

@article{douze2024faiss,
  title={The Faiss Library},
  author={Douze, Matthijs and others},
  journal={arXiv:2401.08281},
  year={2024}
}

@inproceedings{zhang2018personachat,
  title={Personalizing Dialogue Agents: I have a dog, do you have pets too?},
  author={Zhang, Saizheng and others},
  booktitle={ACL},
  year={2018}
}

@article{ge2024personahub,
  title={Scaling Synthetic Data Creation with 1{,}000{,}000{,}000 Personas},
  author={Ge, Tao and others},
  journal={arXiv:2406.20094},
  year={2024}
}

@misc{finepersonas2024,
  title={FinePersonas: 21M Diverse Personas for Synthetic Data},
  author={{Argilla}},
  year={2024},
  howpublished={Dataset},
  url={https://huggingface.co/datasets/argilla/FinePersonas-Synthetic-Email-Conversations}
}

@article{deshpande2023toxicity,
  title={Toxicity in ChatGPT: Analyzing Persona-Assigned Toxicity},
  author={Deshpande, Aditya and others},
  journal={arXiv:2304.05335},
  year={2023}
}

@article{smith2022holisticbias,
  title={“I'm sorry to hear that”: Finding New Biases in Language Models with a Holistic Descriptor Taxonomy},
  author={Smith, Emily M. and others},
  journal={EMNLP},
  year={2022}
}

@inproceedings{parrish2022bbq,
  title={BBQ: A Hand-Built Bias Benchmark for Question Answering},
  author={Parrish, Alicia and others},
  booktitle={Findings of ACL},
  year={2022}
}

@article{moayeri2024worldbench,
  title={Quantifying Geographic Disparities in LLM Factual Recall (WorldBench)},
  author={Moayeri, Mahdi and others},
  journal={ACM Web Conf.},
  year={2024}
}

@article{li2023emotionprompt,
  title={Large Language Models Understand and Can be Enhanced by Emotional Stimuli},
  author={Li, Cheng and others},
  journal={arXiv:2307.11760},
  year={2023}
}

@inproceedings{sabour2024emobench,
  title={EmoBench: Evaluating the Emotional Intelligence of LLMs},
  author={Sabour, Sahand and others},
  booktitle={ACL},
  year={2024}
}

@inproceedings{gehman2020realtoxicity,
  title={RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models},
  author={Gehman, Samuel and others},
  booktitle={Findings of EMNLP},
  year={2020}
}

@inproceedings{hartvigsen2022toxigen,
  title={ToxiGen: A Large-Scale Machine-Generated Dataset for Adversarial and Implicit Hate Speech Detection},
  author={Hartvigsen, Thomas and others},
  booktitle={ACL},
  year={2022}
}

@article{weidinger2023sociotechnical,
  title={Sociotechnical Safety Evaluation of Generative AI Systems},
  author={Weidinger, Laura and others},
  journal={arXiv:2310.11986},
  year={2023}
}

@misc{llamaguard2,
  title={Llama Guard 2: LLM-based Input/Output Safeguard for Human–AI Conversations},
  author={{Meta AI}},
  year={2024},
  howpublished={Model card / technical report},
  url={https://huggingface.co/meta-llama/Meta-Llama-Guard-2-8B}
}

@article{bai2022constitutional,
  title={Constitutional AI: Harmlessness from AI Feedback},
  author={Bai, Yuntao and others},
  journal={arXiv:2212.08073},
  year={2022}
}

@misc{openai2024gpt4o,
  title         = {GPT-4o System Card},
  author        = {{OpenAI}},
  year          = {2024},
  eprint        = {2410.21276},
  archivePrefix = {arXiv},
  primaryClass  = {cs.CL},
  url           = {https://cdn.openai.com/gpt-4o-system-card.pdf}
}

@misc{meta2024llama3,
  title         = {The Llama 3 Herd of Models},
  author        = {{Llama Team, AI@Meta}},
  year          = {2024},
  eprint        = {2407.21783},
  archivePrefix = {arXiv},
  primaryClass  = {cs.CL}
}

@misc{gemma22024,
  title         = {Gemma 2: Improving Open Language Models at a Practical Size},
  author        = {{Gemma Team, Google DeepMind}},
  year          = {2024},
  eprint        = {2408.00118},
  archivePrefix = {arXiv},
  primaryClass  = {cs.CL}
}

@inproceedings{brown2020gpt3,
  title        = {Language Models are Few-Shot Learners},
  author       = {Brown, Tom B. and others},
  booktitle    = {NeurIPS},
  year         = {2020},
  url          = {https://arxiv.org/abs/2005.14165}
}

@article{achiam2023gpt4,
  title        = {GPT-4 Technical Report},
  author       = {Achiam, Josh and others},
  journal      = {arXiv:2303.08774},
  year         = {2023},
  url          = {https://arxiv.org/abs/2303.08774}
}

@article{touvron2023llama2,
  title        = {Llama 2: Open Foundation and Fine-Tuned Chat Models},
  author       = {Touvron, Hugo and others},
  journal      = {arXiv:2307.09288},
  year         = {2023},
  url          = {https://arxiv.org/abs/2307.09288}
}

@article{gemma2024,
  title        = {Gemma: Open Models Based on Gemini Research and Technology},
  author       = {{Gemma Team}},
  journal      = {arXiv:2403.08295},
  year         = {2024},
  url          = {https://arxiv.org/abs/2403.08295}
}

@article{bommasani2021foundation,
  title        = {On the Opportunities and Risks of Foundation Models},
  author       = {Bommasani, Rishi and others},
  journal      = {arXiv:2108.07258},
  year         = {2021},
  url          = {https://arxiv.org/abs/2108.07258}
}

@misc{mckinsey2023genai,
  title        = {The Economic Potential of Generative AI: The Next Productivity Frontier},
  author       = {Chui, Michael and others},
  howpublished = {McKinsey Global Institute Report},
  year         = {2023},
  url          = {https://www.mckinsey.com/~/media/mckinsey/business%20functions/mckinsey%20digital/our%20insights/the%20economic%20potential%20of%20generative%20ai%20the%20next%20productivity%20frontier/the-economic-potential-of-generative-ai-the-next-productivity-frontier.pdf}
}

@article{dong2024icl_survey,
  title        = {A Survey on In-Context Learning},
  author       = {Dong, Qingxiu and others},
  journal      = {EMNLP},
  year         = {2024},
  url          = {https://arxiv.org/abs/2301.00234}
}

@inproceedings{ouyang2022instructgpt,
  title        = {Training Language Models to Follow Instructions with Human Feedback},
  author       = {Ouyang, Long and others},
  booktitle    = {NeurIPS},
  year         = {2022},
  url          = {https://arxiv.org/abs/2203.02155}
}

@inproceedings{rubin2022retrieval,
  title        = {Learning to Retrieve Prompts for In-Context Learning},
  author       = {Rubin, Ohad and Herzig, Jonathan and Berant, Jonathan},
  booktitle    = {NAACL},
  year         = {2022},
  url          = {https://aclanthology.org/2022.naacl-main.191/}
}

@article{wang2023selfinstruct,
  title        = {Self-Instruct: Aligning Language Models with Self-Generated Instructions},
  author       = {Wang, Yizhong and others},
  journal      = {ACL},
  year         = {2023},
  url          = {https://arxiv.org/abs/2212.10560}
}

@inproceedings{zhang2018personachat,
  title        = {Personalizing Dialogue Agents: I Have a Dog, Do You Have Pets Too?},
  author       = {Zhang, Saizheng and others},
  booktitle    = {ACL},
  year         = {2018},
  url          = {https://aclanthology.org/P18-1205/}
}

@article{li2017dailydialog,
  title        = {DailyDialog: A Manually Labelled Multi-turn Dialogue Dataset},
  author       = {Li, Yanran and others},
  journal      = {arXiv:1710.03957},
  year         = {2017},
  url          = {https://arxiv.org/abs/1710.03957}
}

@inproceedings{rashkin2019empathetic,
  title        = {Towards Empathetic Open-domain Conversation Models: A New Benchmark and Dataset},
  author       = {Rashkin, Hannah and others},
  booktitle    = {ACL},
  year         = {2019},
  url          = {https://aclanthology.org/P19-1534/}
}

@inproceedings{budzianowski2018multiwoz,
  title        = {MultiWOZ: A Large-Scale Multi-Domain Wizard-of-Oz Dataset for Task-Oriented Dialogue Modelling},
  author       = {Budzianowski, Pawe{\l} and others},
  booktitle    = {EMNLP},
  year         = {2018},
  url          = {https://aclanthology.org/D18-1547/}
}

@inproceedings{reimers2019sbert,
  title        = {Sentence-BERT: Sentence Embeddings Using Siamese BERT-Networks},
  author       = {Reimers, Nils and Gurevych, Iryna},
  booktitle    = {EMNLP},
  year         = {2019},
  url          = {https://arxiv.org/abs/1908.10084}
}

@article{johnson2017faiss,
  title        = {Billion-Scale Similarity Search with GPUs},
  author       = {Johnson, Jeff and Douze, Matthijs and J{\'e}gou, Herv{\'e}},
  journal      = {arXiv:1702.08734},
  year         = {2017},
  url          = {https://arxiv.org/abs/1702.08734}
}

@inproceedings{lee2022dedup,
  title        = {Deduplicating Training Data Makes Language Models Better},
  author       = {Lee, Katherine and Ippolito, Daphne and Nystrom, Andrew and Zhang, Chiyuan and Eck, Douglas and Callison-Burch, Chris and Carlini, Nicholas},
  booktitle    = {ACL},
  year         = {2022},
  url          = {https://aclanthology.org/2022.acl-long.577/}
}

@article{laranjo2018healthcaresurvey,
  title        = {Conversational Agents in Health Care: Scoping Review and Conceptual Analysis},
  author       = {Laranjo, Liliana and others},
  journal      = {JAMIA},
  year         = {2018},
  url          = {https://academic.oup.com/jamia/article/25/9/1248/5052181}
}

@article{milneives2020healthcare,
  title        = {The Effectiveness and Usability of Conversational Agents in Health Care: Systematic Review},
  author       = {Milne-Ives, Madison and others},
  journal      = {Journal of Medical Internet Research},
  year         = {2020},
  url          = {https://www.jmir.org/2020/10/e20346/}
}

@article{li2021aihospitality,
  title        = {A Systematic Review of AI Technology-Based Service Encounters: Implications for Hospitality and Tourism Operations},
  author       = {Li, Minglong and Yin, Dexiang and Qiu, Hailian and Bai, Billy},
  journal      = {International Journal of Hospitality Management},
  volume       = {95},
  pages        = {102930},
  year         = {2021},
  url          = {https://www.sciencedirect.com/science/article/pii/S0278431921000736}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@inproceedings{min2022metaicl,
  title={MetaICL: Learning to learn in context},
  author={Min, Sewon and Lyu, Xinxi and Holtzman, Ari and Artetxe, Mikel and Lewis, Mike and Hajishirzi, Hannaneh and Zettlemoyer, Luke},
  booktitle={Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={2791--2809},
  year={2022}
}

@article{rubin2022retrieval,
  title={Learning to retrieve prompts for in-context learning},
  author={Rubin, Ohad and Herzig, Jonathan and Berant, Jonathan},
  journal={arXiv preprint arXiv:2112.08633},
  year={2022}
}

@article{wei2022cot,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{kojima2022zeroshot,
  title={Large language models are zero-shot reasoners},
  author={Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={22199--22213},
  year={2022}
}

@article{wu2023selfadaptive,
  title={Self-adaptive in-context learning: An information compression perspective for in-context example selection and ordering},
  author={Wu, Zhiyong and Wang, Yaoxiang and Ye, Jiacheng and Kong, Lingpeng},
  journal={arXiv preprint arXiv:2212.10375},
  year={2023}
}

@article{nguyen2023influence,
  title={Influence functions for in-context learning},
  author={Nguyen, Tuan Dinh and Chen, Shiye and Yang, Zichao and Huang, Xuezhe},
  journal={arXiv preprint arXiv:2305.18290},
  year={2023}
}

@inproceedings{reimers2019sbert,
  title={Sentence-BERT: Sentence embeddings using Siamese BERT-networks},
  author={Reimers, Nils and Gurevych, Iryna},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages={3982--3992},
  year={2019}
}

@inproceedings{lewis2020rag,
  title={Retrieval-augmented generation for knowledge-intensive nlp tasks},
  author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and others},
  booktitle={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9459--9474},
  year={2020}
}

@article{johnson2019faiss,
  title={Billion-scale similarity search with GPUs},
  author={Johnson, Jeff and Douze, Matthijs and J{\'e}gou, Herv{\'e}},
  journal={IEEE Transactions on Big Data},
  volume={7},
  number={3},
  pages={535--547},
  year={2019},
  publisher={IEEE}
}

@misc{pgvector,
  title={pgvector: Open-source vector similarity search for Postgres},
  author={{pgvector contributors}},
  howpublished={\url{https://github.com/pgvector/pgvector}},
  year={2021}
}

@article{wang2023selfinstruct,
  title={Self-instruct: Aligning language models with self-generated instructions},
  author={Wang, Yizhong and Kordi, Yeganeh and Mishra, Swaroop and Liu, Alisa and Smith, Noah A and Khashabi, Daniel and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2212.10560},
  year={2023}
}

@inproceedings{zhang2018personachat,
  title={Personalizing dialogue agents: I have a dog, do you have pets too?},
  author={Zhang, Saizheng and Dinan, Emily and Urbanek, Jack and Szlam, Arthur and Kiela, Douwe and Weston, Jason},
  booktitle={Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={2204--2213},
  year={2018}
}

@article{li2023emotionalstimuli,
  title={Large language models understand and can be enhanced by emotional stimuli},
  author={Li, Cheng and Wang, Jindong and Zhang, Yixuan and Zhu, Kaijie and Hou, Wenxin and Lian, Jianxun and Luo, Fang and Yang, Qiang and Xie, Xing},
  journal={arXiv preprint arXiv:2307.11760},
  year={2023}
}

@article{sabour2024emobench,
  title={EmoBench: Evaluating the emotional intelligence of large language models},
  author={Sabour, Sahand and Liu, Siyang and Zhang, Zheyuan and Liu, June M and Zhou, Jinfeng and Sunaryo, Alvionna S and Gu, Juanzi and Mihalcea, Rada and Poria, Soujanya},
  journal={arXiv preprint arXiv:2402.12071},
  year={2024}
}

@inproceedings{gehman2020realtoxicity,
  title={RealToxicityPrompts: Evaluating neural toxic degeneration in language models},
  author={Gehman, Samuel and Gururangan, Suchin and Sap, Maarten and Choi, Yejin and Smith, Noah A},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2020},
  pages={3356--3369},
  year={2020}
}

@inproceedings{budzianowski2018multiwoz,
  title={MultiWOZ--a large-scale multi-domain Wizard-of-Oz dataset for task-oriented dialogue modelling},
  author={Budzianowski, Pawe{\l} and Wen, Tsung-Hsien and Tseng, Bo-Hsiang and Casanueva, Inigo and Ultes, Stefan and Ramadan, Osman and Ga{\v{s}}i{\'c}, Milica},
  booktitle={Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
  pages={5016--5026},
  year={2018}
}

@inproceedings{zang2020multiwoz22,
  title={MultiWOZ 2.2: A dialogue dataset with additional annotation corrections and state tracking baselines},
  author={Zang, Xiaoxue and Rastogi, Abhinav and Sunkara, Srinivas and Gupta, Raghav and Zhang, Jianguo and Chen, Jindong},
  booktitle={Proceedings of the 2nd Workshop on Natural Language Processing for Conversational AI},
  pages={109--117},
  year={2020}
}

@article{shumailov2024curse,
  title={The Curse of Recursion: Training on Generated Data Makes Models Forget},
  author={Shumailov, Ilia and Shumaylov, Zakhar and Zhao, Yiren and Gal, Yarin and Papernot, Nicolas and Anderson, Ross},
  journal={Nature},
  volume={631},
  pages={755--763},
  year={2024}
}

@article{carlini2024extracting,
  title={Extracting Training Data from Large Language Models},
  author={Carlini, Nicholas and Tramer, Florian and Wallace, Eric and Jagielski, Matthew and Herbert-Voss, Ariel and Lee, Katherine and Roberts, Adam and Brown, Tom and Song, Dawn and Erlingsson, Ulfar and others},
  journal={Communications of the ACM},
  volume={67},
  number={3},
  pages={64--72},
  year={2024}
}

@article{deshpande2023toxicity,
  title={Toxicity in ChatGPT: Analyzing Persona-assigned Language Models},
  author={Deshpande, Ameet and Murahari, Vishvak and Rajpurohit, Tanmay and Kalyan, Ashwin and Narasimhan, Karthik},
  journal={Findings of EMNLP},
  year={2023}
}

@article{liu2024synthetic,
  title={Synthetic Data Generation for Large Language Models: A Survey},
  author={Liu, Ruibo and Wei, Jerry and Liu, Fangyu and Si, Chenglei and Zhang, Yanzhe and Rao, Jinmeng and Zheng, Steven and Peng, Daiyi and Yang, Diyi and Zhou, Denny and Dai, Andrew M},
  journal={arXiv preprint arXiv:2401.02524},
  year={2024}
}

@article{long2024llms,
  title={LLMs as Data Generators: A Systematic Literature Review},
  author={Long, Shilong and Pei, Jiliang and Luo, Liang and Xia, Tianyang and Chen, Jiarong and Zhang, Zhuoran and Xiao, Xinwang and Kuang, Wenyue},
  journal={arXiv preprint arXiv:2402.10760},
  year={2024}
}

@article{veselovsky2023llmsecurity,
  title={Artificial Intelligence Deception: A Survey of Synthetic Content Generation and Detection},
  author={Veselovsky, Valeriia and Ribeiro, Manoel Horta and Arora, Akhil and Martin, Jacob and West, Robert},
  journal={arXiv preprint arXiv:2308.14752},
  year={2023}
}

@article{yu2024large,
  title={Large Language Model as Attributed Training Data Generator: A Tale of Diversity and Bias},
  author={Yu, Yue and Zhuang, Yuchen and Zhang, Jieyu and Meng, Yu and Ratner, Alexander and Krishna, Ranjay and Shen, Jiaming and Zhang, Chao},
  journal={NeurIPS Datasets and Benchmarks},
  year={2024}
}

@article{nikolenko2021synthetic,
  title={Synthetic Data for Deep Learning},
  author={Nikolenko, Sergey I},
  journal={Springer Optimization and Its Applications},
  volume={174},
  year={2021}
}

@inproceedings{lu2024machineunlearning,
  title={Machine Unlearning: A Survey},
  author={Lu, Yiming and Wang, Jinghan and Wang, Jiaxi and Zhang, Yudong and Zhang, Hang},
  booktitle={ACM Computing Surveys},
  year={2024}
}

@article{karamolegkou2023copyright,
  title={Copyright Violations and Large Language Models},
  author={Karamolegkou, Antonia and Li, Jiaang and Zhou, Li and Søgaard, Anders},
  journal={EMNLP},
  year={2023}
}

@inproceedings{liu2024perplexity,
  title={Perplexity as a Measure of Language Model Performance},
  author={Liu, Yang and Iter, Dan and Xu, Yichong and Wang, Shuohang and Xu, Ruochen and Zhu, Chenguang},
  booktitle={ACL},
  year={2024}
}

@article{zhang2024bertscore,
  title={BERTScore: Evaluating Text Generation with BERT},
  author={Zhang, Tianyi and Kishore, Varsha and Wu, Felix and Weinberger, Kilian Q and Artzi, Yoav},
  journal={ICLR},
  year={2024}
}

@article{lin2024rouge,
  title={ROUGE: A Package for Automatic Evaluation of Summaries},
  author={Lin, Chin-Yew},
  journal={ACL Workshop},
  year={2024}
}

@article{ji2024safety,
  title={AI Safety and Security: A Survey},
  author={Ji, Ziwei and Yu, Tiezheng and Xu, Yan and Lee, Nayeon and Ishii, Etsuko and Fung, Pascale},
  journal={arXiv preprint arXiv:2402.13503},
  year={2024}
}

@article{weidinger2024sociotechnical,
  title={Sociotechnical Safety Evaluation of Generative AI Systems},
  author={Weidinger, Laura and Uesato, Jonathan and Rauh, Maribeth and Griffin, Conor and Huang, Po-Sen and Mellor, John and Glaese, Amelia and Cheng, Myra and Balle, Borja and Kasirzadeh, Atoosa and others},
  journal={arXiv preprint arXiv:2310.11986},
  year={2024}
}

@misc{chan2024scalingsyntheticdatacreation,
  title={Scaling Synthetic Data Creation with 1,000,000,000 Personas},
  author={Chan, Xin and Wang, Xiaoyang and Yu, Dian and Mi, Haitao and Yu, Dong},
  year={2024},
  eprint={2406.20094},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2406.20094}
}

@misc{finepersonas2024,
  title={FinePersonas: A Collection of 21 Million Detailed Personas for Diverse Synthetic Text Generation},
  author={{Argilla}},
  year={2024},
  howpublished={\url{https://huggingface.co/datasets/argilla/FinePersonas-v0.1}},
  note={Based on PersonaHub methodology and FineWeb-Edu dataset}
}

@software{lozhkov2024fineweb-edu,
  author={Lozhkov, Anton and Ben Allal, Loubna and von Werra, Leandro and Wolf, Thomas},
  title={FineWeb-Edu},
  month={May},
  year={2024},
  doi={10.57967/hf/2497},
  url={https://huggingface.co/datasets/HuggingFaceFW/fineweb-edu}
}

@article{radford2019gpt2,
  title={Language Models are Unsupervised Multitask Learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  journal={OpenAI blog},
  year={2019}
}

@inproceedings{qian2021hrmultiwoz,
  title={Annotation Inconsistency and Entity Bias in MultiWOZ},
  author={Qian, Kun and Mehri, Shafaatunnur and Zhao, Yi and Eskenazi, Maxine},
  booktitle={Proceedings of the 22nd Annual Meeting of the Special Interest Group on Discourse and Dialogue},
  pages={326--337},
  year={2021}
}

@article{jandaghi2024spc,
  title={Faithful Persona-based Conversational Dataset Generation with Large Language Models},
  author={Jandaghi, Pegah and Fang, XiangHai and Soltani, Aria and Sedoc, João},
  journal={arXiv preprint arXiv:2312.10007},
  year={2024}
}

@inproceedings{jang2023upcs,
  title={Personalized Somatic Awareness through Guided Dialogue with Large Language Models},
  author={Jang, Yebin and Shin, Hyunwoo and Kim, Jihwan and others},
  booktitle={ACL Findings},
  year={2023}
}

@article{kim2024tdeval,
  title={TD-EVAL: Quantifying Task-Oriented Dialogue Quality with Turn-Level and Dialogue-Level Metrics},
  author={Kim, Seokhwan and Liu, Yang and Jin, Di and Gurevych, Iryna},
  journal={arXiv preprint arXiv:2405.09588},
  year={2024}
}

@article{han2024wildguard,
  title={WildGuard: Open One-Stop Moderation Tools for Safety Risks, Jailbreaks, and Refusals of LLMs},
  author={Han, Seungju and Kim, Kavel and Yoo, Seungwhan and Park, Youngwhan and Kim, Sang-Woo and others},
  journal={arXiv preprint arXiv:2406.18495},
  year={2024}
}

@misc{detoxify2021,
  title={Detoxify: A Python library to identify and score toxic comments},
  author={Hanu, Laura and Unitary Team},
  howpublished={\url{https://github.com/unitaryai/detoxify}},
  year={2021}
}
