#!/usr/bin/env python3
"""
Mock-based validation test for dataset loader extraction
Tests structure without requiring actual dependencies
"""

import sys
import os
from unittest.mock import Mock, patch

# Add parent directory to path to import modules
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))

def test_dataset_loader_with_mocks():
    """Test dataset loader using mocks to avoid dependency issues"""

    print("üîç Validating dataset loader with mocks...")

    # Mock the datasets module
    mock_datasets = Mock()
    mock_dataset_dict = Mock()
    mock_dataset_dict.load_from_disk.return_value = {'train': Mock()}
    mock_datasets.load_from_disk.return_value = Mock()
    mock_datasets.DatasetDict = mock_dataset_dict

    all_passed = True

    with patch.dict('sys.modules', {'datasets': mock_datasets}):
        # Now import our modules
        from dialogue_generation.data.dataset_loader import (
            DatasetLoader, PersonaManager, DialogueProcessor, DataRepository
        )

        # Test DatasetLoader
        print("  üìã Testing DatasetLoader...")
        try:
            loader = DatasetLoader()

            # Check required methods exist
            required_methods = ['load_dataset', 'load_persona_dataset']
            for method_name in required_methods:
                if not hasattr(loader, method_name):
                    print(f"    ‚ùå Missing method: {method_name}")
                    all_passed = False
                elif not callable(getattr(loader, method_name)):
                    print(f"    ‚ùå Method not callable: {method_name}")
                    all_passed = False
                else:
                    print(f"    ‚úÖ Has method: {method_name}")

        except Exception as e:
            print(f"    ‚ùå DatasetLoader initialization failed: {e}")
            all_passed = False

        # Test PersonaManager with mock data
        print("  üë§ Testing PersonaManager...")
        try:
            # Create realistic mock persona dataset
            mock_persona_data = {
                'cluster_label': [1, 2, 1, 3, 2],
                'summary_label': ['["helpful"]', '["creative"]', '["helpful", "analytical"]', '["professional"]', '["creative"]'],
                'persona': [
                    'I am a helpful assistant.',
                    'I enjoy creative problem-solving.',
                    'I provide analytical and helpful responses.',
                    'I maintain a professional demeanor.',
                    'I think outside the box.'
                ]
            }

            # Create mock dataset object that behaves like the real one
            class MockPersonaDataset:
                def __init__(self, data):
                    self.data = data

                def __getitem__(self, key):
                    if isinstance(key, str):
                        # Accessing by column name (like dataset['cluster_label'])
                        return self.data[key]
                    elif isinstance(key, int):
                        # Accessing by row index (like dataset[0])
                        return {col: values[key] for col, values in self.data.items()}
                    else:
                        raise TypeError(f"Invalid key type: {type(key)}")

                def __len__(self):
                    return len(self.data['persona'])

            mock_dataset = MockPersonaDataset(mock_persona_data)
            persona_manager = PersonaManager(mock_dataset)

            # Check required methods exist
            required_methods = ['safe_eval', 'get_summary_labels', 'populate_persona_dicts', 'select_random_persona']
            for method_name in required_methods:
                if not hasattr(persona_manager, method_name):
                    print(f"    ‚ùå Missing method: {method_name}")
                    all_passed = False
                elif not callable(getattr(persona_manager, method_name)):
                    print(f"    ‚ùå Method not callable: {method_name}")
                    all_passed = False
                else:
                    print(f"    ‚úÖ Has method: {method_name}")

            # Test persona selection
            persona = persona_manager.select_random_persona()
            if persona in mock_persona_data['persona']:
                print(f"    ‚úÖ Persona selection works: '{persona[:30]}...'")
            else:
                print(f"    ‚ùå Invalid persona selected: {persona}")
                all_passed = False

            # Test cluster and summary dicts populated
            if len(persona_manager.cluster_dict) > 0:
                print(f"    ‚úÖ Cluster dict populated: {len(persona_manager.cluster_dict)} clusters")
            else:
                print(f"    ‚ùå Cluster dict not populated")
                all_passed = False

            if len(persona_manager.summary_dict) > 0:
                print(f"    ‚úÖ Summary dict populated: {len(persona_manager.summary_dict)} summaries")
            else:
                print(f"    ‚ùå Summary dict not populated")
                all_passed = False

            # Test safe_eval functionality
            test_cases = [
                ('["item1", "item2"]', ["item1", "item2"]),
                ('invalid syntax', []),
                ('"single_string"', "single_string"),
                ('123', 123)
            ]

            for input_str, expected in test_cases:
                result = persona_manager.safe_eval(input_str)
                if result == expected:
                    print(f"    ‚úÖ safe_eval('{input_str}') = {result}")
                else:
                    print(f"    ‚ùå safe_eval('{input_str}') = {result}, expected {expected}")
                    all_passed = False

        except Exception as e:
            print(f"    ‚ùå PersonaManager testing failed: {e}")
            import traceback
            traceback.print_exc()
            all_passed = False

        # Test DialogueProcessor
        print("  üí¨ Testing DialogueProcessor...")
        try:
            processor = DialogueProcessor()

            # Check required methods exist
            required_methods = ['extract_dialogue', 'generate_base_conversation']
            for method_name in required_methods:
                if not hasattr(processor, method_name):
                    print(f"    ‚ùå Missing method: {method_name}")
                    all_passed = False
                elif not callable(getattr(processor, method_name)):
                    print(f"    ‚ùå Method not callable: {method_name}")
                    all_passed = False
                else:
                    print(f"    ‚úÖ Has method: {method_name}")

            # Test with realistic mock dialogue data
            mock_dialogue = {
                "dialogue_id": "test_dialogue_001",
                "turns": {
                    "speaker": [0, 1, 0, 1, 0, 1],
                    "utterance": [
                        "Hello, I'd like to book a hotel",
                        "Of course! I'd be happy to help you book a hotel. What city are you looking to stay in?",
                        "I need a room in Paris for next weekend",
                        "Great! Let me search for available hotels in Paris. What's your budget range?",
                        "Around 150 euros per night",
                        "Perfect! I found several options in that range. Would you prefer a central location?"
                    ],
                    "turn_id": [1, 2, 3, 4, 5, 6]
                }
            }

            # Test dialogue extraction
            turns = processor.extract_dialogue(mock_dialogue)
            if len(turns) == 6:
                print(f"    ‚úÖ Dialogue extraction works: {len(turns)} turns")
            else:
                print(f"    ‚ùå Wrong number of turns extracted: {len(turns)}, expected 6")
                all_passed = False

            # Check turn structure
            if turns:
                required_keys = ['turn_id', 'speaker', 'utterance']
                if all(key in turns[0] for key in required_keys):
                    print(f"    ‚úÖ Turn structure correct: {list(turns[0].keys())}")
                else:
                    print(f"    ‚ùå Turn structure incorrect: {turns[0]}")
                    all_passed = False

                # Check speaker mapping
                expected_speakers = ["USER", "ASSISTANT", "USER", "ASSISTANT", "USER", "ASSISTANT"]
                actual_speakers = [turn['speaker'] for turn in turns]
                if actual_speakers == expected_speakers:
                    print(f"    ‚úÖ Speaker mapping correct: {actual_speakers}")
                else:
                    print(f"    ‚ùå Speaker mapping incorrect: {actual_speakers}")
                    all_passed = False

            # Test base conversation generation
            base_conv = processor.generate_base_conversation(turns)
            if "USER:" in base_conv and "ASSISTANT:" in base_conv:
                print(f"    ‚úÖ Base conversation generation works")
                # Check format
                lines = base_conv.split("\\n")
                if len(lines) == 6:
                    print(f"    ‚úÖ Correct number of conversation lines: {len(lines)}")
                else:
                    print(f"    ‚ùå Wrong number of conversation lines: {len(lines)}, expected 6")
                    all_passed = False
            else:
                print(f"    ‚ùå Base conversation format incorrect")
                all_passed = False

        except Exception as e:
            print(f"    ‚ùå DialogueProcessor testing failed: {e}")
            import traceback
            traceback.print_exc()
            all_passed = False

        # Test DataRepository
        print("  üóÉÔ∏è Testing DataRepository...")
        try:
            repo = DataRepository()

            # Check required methods exist
            required_methods = ['get_dataset_info', 'select_random_persona', 'extract_and_process_dialogue', 'get_dialogue_example']
            for method_name in required_methods:
                if not hasattr(repo, method_name):
                    print(f"    ‚ùå Missing method: {method_name}")
                    all_passed = False
                elif not callable(getattr(repo, method_name)):
                    print(f"    ‚ùå Method not callable: {method_name}")
                    all_passed = False
                else:
                    print(f"    ‚úÖ Has method: {method_name}")

            # Check properties exist
            required_properties = ['dataset_loader', 'dialogue_processor']
            for prop_name in required_properties:
                if not hasattr(repo, prop_name):
                    print(f"    ‚ùå Missing property: {prop_name}")
                    all_passed = False
                else:
                    print(f"    ‚úÖ Has property: {prop_name}")

        except Exception as e:
            print(f"    ‚ùå DataRepository testing failed: {e}")
            import traceback
            traceback.print_exc()
            all_passed = False

    if all_passed:
        print("\nüéâ DATASET LOADER MOCK VALIDATION PASSED!")
        print("‚úÖ All classes and methods properly extracted - safe to proceed")
        return True
    else:
        print("\n‚ùå DATASET LOADER MOCK VALIDATION FAILED!")
        print("üö® DO NOT PROCEED - Fix dataset loader structure first")
        return False

def show_dataset_loader_summary():
    """Show summary of dataset loader structure"""
    print("\nüìä DATASET LOADER SUMMARY:")
    print("=" * 50)
    print("Classes extracted:")
    print("  - DatasetLoader: Handles Multi-WOZ and persona dataset loading")
    print("  - PersonaManager: Manages persona selection and clustering")
    print("  - DialogueProcessor: Processes dialogue extraction and formatting")
    print("  - DataRepository: Central data management hub")
    print("\nKey functionality:")
    print("  ‚úÖ Dataset loading (Multi-WOZ format)")
    print("  ‚úÖ Persona dataset loading and management")
    print("  ‚úÖ Dialogue turn extraction and processing")
    print("  ‚úÖ Base conversation generation")
    print("  ‚úÖ Persona clustering and selection")
    print("  ‚úÖ Safe evaluation of string data")
    print("\nStructure preserved:")
    print("  ‚úÖ Exact method signatures from original")
    print("  ‚úÖ Error handling preserved")
    print("  ‚úÖ Logging integration maintained")
    print("=" * 50)

if __name__ == "__main__":
    try:
        success = test_dataset_loader_with_mocks()
        if success:
            show_dataset_loader_summary()
        exit(0 if success else 1)
    except Exception as e:
        print(f"‚ùå Validation failed with error: {e}")
        import traceback
        traceback.print_exc()
        exit(1)