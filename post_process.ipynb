{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries in dataset: 50688\n",
      "Entries with both {'attraction', 'restaurant'}: 2532\n",
      "Number of entries to remove (50%): 1266\n",
      "Selected entries for removal.\n",
      "Updated dataset size: 49422\n",
      "Removed entries size: 1266\n",
      "Updated dataset saved to updated_dataset.jsonl\n",
      "Removed entries saved to removed_entries.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "# Define file paths\n",
    "INPUT_FILE = 'generated_dialogues.jsonl'          # Replace with your actual file name\n",
    "OUTPUT_FILE = 'updated_dataset.jsonl'      # The file after removal\n",
    "REMOVED_FILE = 'removed_entries.jsonl'     # File to store removed entries\n",
    "\n",
    "# Define the target services\n",
    "TARGET_SERVICES = {'attraction', 'restaurant'}\n",
    "\n",
    "# Optional: Set a random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "def standardize_services(services_list):\n",
    "    \"\"\"\n",
    "    Standardize service names:\n",
    "    - Convert to lowercase.\n",
    "    - Singularize if necessary (e.g., 'restaurants' -> 'restaurant').\n",
    "    \"\"\"\n",
    "    standardized = set()\n",
    "    for service in services_list:\n",
    "        service = service.lower().strip()\n",
    "        if service.endswith('s') and service != 'bus':  # Retain 'bus' as it's already singular\n",
    "            service = service.rstrip('s')  # Simple singularization\n",
    "        standardized.add(service)\n",
    "    return standardized\n",
    "\n",
    "def main():\n",
    "    # First pass: Identify all 'dialogue_id's with both target services\n",
    "    matching_dialogue_ids = []\n",
    "    total_entries = 0\n",
    "\n",
    "    with open(INPUT_FILE, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            total_entries += 1\n",
    "            entry = json.loads(line)\n",
    "            services = entry.get('services', [])\n",
    "            standardized_services = standardize_services(services)\n",
    "            if TARGET_SERVICES.issubset(standardized_services):\n",
    "                dialogue_id = entry.get('dialogue_id')\n",
    "                if dialogue_id:\n",
    "                    matching_dialogue_ids.append(dialogue_id)\n",
    "\n",
    "    total_matching = len(matching_dialogue_ids)\n",
    "    print(f\"Total entries in dataset: {total_entries}\")\n",
    "    print(f\"Entries with both {TARGET_SERVICES}: {total_matching}\")\n",
    "\n",
    "    if total_matching == 0:\n",
    "        print(\"No matching entries found. No removal performed.\")\n",
    "        return\n",
    "\n",
    "    # Determine number of entries to remove (50%)\n",
    "    num_to_remove = total_matching // 2\n",
    "    print(f\"Number of entries to remove (50%): {num_to_remove}\")\n",
    "\n",
    "    # Randomly select 'dialogue_id's to remove\n",
    "    entries_to_remove_ids = set(random.sample(matching_dialogue_ids, num_to_remove))\n",
    "    print(\"Selected entries for removal.\")\n",
    "\n",
    "    # Second pass: Write to updated and removed files\n",
    "    updated_count = 0\n",
    "    removed_count = 0\n",
    "\n",
    "    with open(INPUT_FILE, 'r', encoding='utf-8') as fin, \\\n",
    "         open(OUTPUT_FILE, 'w', encoding='utf-8') as fout, \\\n",
    "         open(REMOVED_FILE, 'w', encoding='utf-8') as fremoved:\n",
    "\n",
    "        for line in fin:\n",
    "            entry = json.loads(line)\n",
    "            dialogue_id = entry.get('dialogue_id')\n",
    "            if dialogue_id in entries_to_remove_ids:\n",
    "                fremoved.write(line)\n",
    "                removed_count += 1\n",
    "            else:\n",
    "                fout.write(line)\n",
    "                updated_count += 1\n",
    "\n",
    "    print(f\"Updated dataset size: {updated_count}\")\n",
    "    print(f\"Removed entries size: {removed_count}\")\n",
    "    print(f\"Updated dataset saved to {OUTPUT_FILE}\")\n",
    "    print(f\"Removed entries saved to {REMOVED_FILE}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
